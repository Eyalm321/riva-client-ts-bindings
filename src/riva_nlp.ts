// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.0.2
//   protoc               v5.28.0
// source: riva/proto/riva_nlp.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import {
  type CallOptions,
  ChannelCredentials,
  Client,
  type ClientOptions,
  type ClientUnaryCall,
  type handleUnaryCall,
  makeGenericClientConstructor,
  Metadata,
  type ServiceError,
  type UntypedServiceImplementation,
} from "@grpc/grpc-js";
import { RequestId } from "./riva_common";

export const protobufPackage = "nvidia.riva.nlp";

export interface RivaNLPConfigRequest {
  /**
   * If model is specified only return config for model, otherwise return all
   * configs.
   */
  modelName: string;
}

export interface RivaNLPConfigResponse {
  modelConfig: RivaNLPConfigResponse_Config[];
}

export interface RivaNLPConfigResponse_Config {
  modelName: string;
  parameters: { [key: string]: string };
}

export interface RivaNLPConfigResponse_Config_ParametersEntry {
  key: string;
  value: string;
}

/**
 * NLPModelParams is a metadata message that is included in every request
 * message used by the Core NLP Service and is used to specify model
 * characteristics/requirements
 */
export interface NLPModelParams {
  /**
   * Requested model to use. If specified, this takes preference over
   * language_code.
   */
  modelName: string;
  /**
   * Specify language of the supplied text as a
   * [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
   * Defaults to "en-US" if not set.
   */
  languageCode: string;
}

/**
 * TextTransformRequest is a request type intended for services like
 * TransformText which take an arbitrary text input
 */
export interface TextTransformRequest {
  /**
   * Each repeated text element is handled independently for handling multiple
   * input strings with a single request
   */
  text: string[];
  topN: number;
  model:
    | NLPModelParams
    | undefined;
  /**
   * The ID to be associated with the request. If provided, this will be
   * returned in the corresponding response.
   */
  id: RequestId | undefined;
}

/**
 * TextTransformResponse is returned by the TransformText method. Responses
 * are returned in the same order as they were requested.
 */
export interface TextTransformResponse {
  text: string[];
  /** The ID associated with the request */
  id: RequestId | undefined;
}

/** TextClassRequest is the input message to the ClassifyText service. */
export interface TextClassRequest {
  /**
   * Each repeated text element is handled independently for handling multiple
   * input strings with a single request
   *
   * @deprecated
   */
  text: string[];
  /**
   * Return the top N classification results for each input. 0 or 1 will return
   * top class, otherwise N. Note: Current disabled.
   *
   * @deprecated
   */
  topN: number;
  /** @deprecated */
  model:
    | NLPModelParams
    | undefined;
  /**
   * The ID to be associated with the request. If provided, this will be
   * returned in the corresponding response.
   *
   * @deprecated
   */
  id: RequestId | undefined;
}

/** Classification messages return a class name and corresponding score */
export interface Classification {
  /** @deprecated */
  className: string;
  /** @deprecated */
  score: number;
}

/** Span of a particular result */
export interface Span {
  /** @deprecated */
  start: number;
  /** @deprecated */
  end: number;
}

/**
 * ClassificationResults contain zero or more Classification messages
 * If the number of Classifications is > 1, top_n > 1 must have been
 * specified.
 */
export interface ClassificationResult {
  /** @deprecated */
  labels: Classification[];
}

/** TextClassResponse is the return message from the ClassifyText service. */
export interface TextClassResponse {
  /** @deprecated */
  results: ClassificationResult[];
  /**
   * The ID associated with the request
   *
   * @deprecated
   */
  id: RequestId | undefined;
}

/** TokenClassRequest is the input message to the ClassifyText service. */
export interface TokenClassRequest {
  /**
   * Each repeated text element is handled independently for handling multiple
   * input strings with a single request
   *
   * @deprecated
   */
  text: string[];
  /**
   * Return the top N classification results for each input. 0 or 1 will return
   * top class, otherwise N.
   * Note: Current disabled.
   *
   * @deprecated
   */
  topN: number;
  /** @deprecated */
  model:
    | NLPModelParams
    | undefined;
  /**
   * The ID to be associated with the request. If provided, this will be
   * returned in the corresponding response.
   *
   * @deprecated
   */
  id: RequestId | undefined;
}

/**
 * TokenClassValue is used to correlate an input token with its classification
 * results
 */
export interface TokenClassValue {
  /** @deprecated */
  token: string;
  /** @deprecated */
  label: Classification[];
  /** @deprecated */
  span: Span[];
}

/**
 * TokenClassSequence is used for returning a sequence of TokenClassValue
 * objects in the original order of input tokens
 */
export interface TokenClassSequence {
  /** @deprecated */
  results: TokenClassValue[];
}

/** TokenClassResponse returns a single TokenClassSequence per input request */
export interface TokenClassResponse {
  /** @deprecated */
  results: TokenClassSequence[];
  /**
   * The ID associated with the request
   *
   * @deprecated
   */
  id: RequestId | undefined;
}

/**
 * AnalyzeIntentContext is reserved for future use when we may send context back
 * in a a variety of different formats (including raw neural network hidden
 * states)
 */
export interface AnalyzeIntentContext {
}

/**
 * AnalyzeIntentOptions is an optional configuration message to be sent as part
 * of an AnalyzeIntentRequest with query metadata
 */
export interface AnalyzeIntentOptions {
  /** @deprecated */
  previousIntent?:
    | string
    | undefined;
  /** @deprecated */
  vectors?:
    | AnalyzeIntentContext
    | undefined;
  /**
   * Optional domain field. Domain must be supported otherwise an error will be
   * returned. If left blank, a domain detector will be run first and then the
   * query routed to the appropriate intent classifier (if it exists)
   *
   * @deprecated
   */
  domain: string;
  /**
   * Optional language field. Assumed to be "en-US" if not specified.
   *
   * @deprecated
   */
  lang: string;
}

/** AnalyzeIntentRequest is the input message for the AnalyzeIntent service */
export interface AnalyzeIntentRequest {
  /**
   * The string to analyze for intent and slots
   *
   * @deprecated
   */
  query: string;
  /**
   * Optional configuration for the request, including providing context from
   * previous turns and hardcoding a domain/language
   *
   * @deprecated
   */
  options:
    | AnalyzeIntentOptions
    | undefined;
  /**
   * The ID to be associated with the request. If provided, this will be
   * returned in the corresponding response.
   *
   * @deprecated
   */
  id: RequestId | undefined;
}

/**
 * AnalyzeIntentResponse is returned by the AnalyzeIntent service, and includes
 * information related to the query's intent, (optionally) slot data, and its
 * domain.
 */
export interface AnalyzeIntentResponse {
  /**
   * Intent classification result, including the label and score
   *
   * @deprecated
   */
  intent:
    | Classification
    | undefined;
  /**
   * List of tokens explicitly marked as filling a slot relevant to the intent,
   * where the tokens may not exactly match the input (based on the recombined
   * values after tokenization)
   *
   * @deprecated
   */
  slots: TokenClassValue[];
  /**
   * Returns the inferred domain for the query if not hardcoded in the request.
   * In the case where the domain was hardcoded in AnalyzeIntentRequest, the
   * returned domain is an exact match to the request. In the case where no
   * domain matches the query, intent and slots will be unset.
   *
   * DEPRECATED, use Classification domain field.
   *
   * @deprecated
   */
  domainStr: string;
  /**
   * Returns the inferred domain for the query if not hardcoded in the request.
   * In the case where the domain was hardcoded in AnalyzeIntentRequest, the
   * returned domain is an exact match to the request. In the case where no
   * domain matches the query, intent and slots will be unset.
   *
   * @deprecated
   */
  domain:
    | Classification
    | undefined;
  /**
   * The ID associated with the request
   *
   * @deprecated
   */
  id: RequestId | undefined;
}

/**
 * AnalyzeEntitiesOptions is an optional configuration message to be sent as
 * part of an AnalyzeEntitiesRequest with query metadata
 */
export interface AnalyzeEntitiesOptions {
  /**
   * Optional language field. Assumed to be "en-US" if not specified.
   *
   * @deprecated
   */
  lang: string;
}

/** AnalyzeEntitiesRequest is the input message for the AnalyzeEntities service */
export interface AnalyzeEntitiesRequest {
  /**
   * The string to analyze for intent and slots
   *
   * @deprecated
   */
  query: string;
  /**
   * Optional configuration for the request, including providing context from
   * previous turns and hardcoding a domain/language
   *
   * @deprecated
   */
  options:
    | AnalyzeEntitiesOptions
    | undefined;
  /**
   * The ID to be associated with the request. If provided, this will be
   * returned in the corresponding response.
   *
   * @deprecated
   */
  id: RequestId | undefined;
}

export interface NaturalQueryRequest {
  /**
   * The natural language query
   *
   * @deprecated
   */
  query: string;
  /**
   * Maximum number of answers to return for the query. Defaults to 1 if not
   * set.
   *
   * @deprecated
   */
  topN: number;
  /**
   * Context to search with the above query
   *
   * @deprecated
   */
  context: string;
  /**
   * The ID to be associated with the request. If provided, this will be
   * returned in the corresponding response.
   *
   * @deprecated
   */
  id: RequestId | undefined;
}

export interface NaturalQueryResult {
  /**
   * text which answers the query
   *
   * @deprecated
   */
  answer: string;
  /**
   * Score representing confidence in result
   *
   * @deprecated
   */
  score: number;
}

export interface NaturalQueryResponse {
  /** @deprecated */
  results: NaturalQueryResult[];
  /**
   * The ID associated with the request
   *
   * @deprecated
   */
  id: RequestId | undefined;
}

function createBaseRivaNLPConfigRequest(): RivaNLPConfigRequest {
  return { modelName: "" };
}

export const RivaNLPConfigRequest = {
  encode(message: RivaNLPConfigRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.modelName !== "") {
      writer.uint32(10).string(message.modelName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RivaNLPConfigRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRivaNLPConfigRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.modelName = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RivaNLPConfigRequest {
    return { modelName: isSet(object.modelName) ? globalThis.String(object.modelName) : "" };
  },

  toJSON(message: RivaNLPConfigRequest): unknown {
    const obj: any = {};
    if (message.modelName !== "") {
      obj.modelName = message.modelName;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<RivaNLPConfigRequest>, I>>(base?: I): RivaNLPConfigRequest {
    return RivaNLPConfigRequest.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<RivaNLPConfigRequest>, I>>(object: I): RivaNLPConfigRequest {
    const message = createBaseRivaNLPConfigRequest();
    message.modelName = object.modelName ?? "";
    return message;
  },
};

function createBaseRivaNLPConfigResponse(): RivaNLPConfigResponse {
  return { modelConfig: [] };
}

export const RivaNLPConfigResponse = {
  encode(message: RivaNLPConfigResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.modelConfig) {
      RivaNLPConfigResponse_Config.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RivaNLPConfigResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRivaNLPConfigResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.modelConfig.push(RivaNLPConfigResponse_Config.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RivaNLPConfigResponse {
    return {
      modelConfig: globalThis.Array.isArray(object?.modelConfig)
        ? object.modelConfig.map((e: any) => RivaNLPConfigResponse_Config.fromJSON(e))
        : [],
    };
  },

  toJSON(message: RivaNLPConfigResponse): unknown {
    const obj: any = {};
    if (message.modelConfig?.length) {
      obj.modelConfig = message.modelConfig.map((e) => RivaNLPConfigResponse_Config.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<RivaNLPConfigResponse>, I>>(base?: I): RivaNLPConfigResponse {
    return RivaNLPConfigResponse.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<RivaNLPConfigResponse>, I>>(object: I): RivaNLPConfigResponse {
    const message = createBaseRivaNLPConfigResponse();
    message.modelConfig = object.modelConfig?.map((e) => RivaNLPConfigResponse_Config.fromPartial(e)) || [];
    return message;
  },
};

function createBaseRivaNLPConfigResponse_Config(): RivaNLPConfigResponse_Config {
  return { modelName: "", parameters: {} };
}

export const RivaNLPConfigResponse_Config = {
  encode(message: RivaNLPConfigResponse_Config, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.modelName !== "") {
      writer.uint32(10).string(message.modelName);
    }
    Object.entries(message.parameters).forEach(([key, value]) => {
      RivaNLPConfigResponse_Config_ParametersEntry.encode({ key: key as any, value }, writer.uint32(18).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RivaNLPConfigResponse_Config {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRivaNLPConfigResponse_Config();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.modelName = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          const entry2 = RivaNLPConfigResponse_Config_ParametersEntry.decode(reader, reader.uint32());
          if (entry2.value !== undefined) {
            message.parameters[entry2.key] = entry2.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RivaNLPConfigResponse_Config {
    return {
      modelName: isSet(object.modelName) ? globalThis.String(object.modelName) : "",
      parameters: isObject(object.parameters)
        ? Object.entries(object.parameters).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: RivaNLPConfigResponse_Config): unknown {
    const obj: any = {};
    if (message.modelName !== "") {
      obj.modelName = message.modelName;
    }
    if (message.parameters) {
      const entries = Object.entries(message.parameters);
      if (entries.length > 0) {
        obj.parameters = {};
        entries.forEach(([k, v]) => {
          obj.parameters[k] = v;
        });
      }
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<RivaNLPConfigResponse_Config>, I>>(base?: I): RivaNLPConfigResponse_Config {
    return RivaNLPConfigResponse_Config.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<RivaNLPConfigResponse_Config>, I>>(object: I): RivaNLPConfigResponse_Config {
    const message = createBaseRivaNLPConfigResponse_Config();
    message.modelName = object.modelName ?? "";
    message.parameters = Object.entries(object.parameters ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    return message;
  },
};

function createBaseRivaNLPConfigResponse_Config_ParametersEntry(): RivaNLPConfigResponse_Config_ParametersEntry {
  return { key: "", value: "" };
}

export const RivaNLPConfigResponse_Config_ParametersEntry = {
  encode(
    message: RivaNLPConfigResponse_Config_ParametersEntry,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RivaNLPConfigResponse_Config_ParametersEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRivaNLPConfigResponse_Config_ParametersEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RivaNLPConfigResponse_Config_ParametersEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: RivaNLPConfigResponse_Config_ParametersEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<RivaNLPConfigResponse_Config_ParametersEntry>, I>>(
    base?: I,
  ): RivaNLPConfigResponse_Config_ParametersEntry {
    return RivaNLPConfigResponse_Config_ParametersEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<RivaNLPConfigResponse_Config_ParametersEntry>, I>>(
    object: I,
  ): RivaNLPConfigResponse_Config_ParametersEntry {
    const message = createBaseRivaNLPConfigResponse_Config_ParametersEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseNLPModelParams(): NLPModelParams {
  return { modelName: "", languageCode: "" };
}

export const NLPModelParams = {
  encode(message: NLPModelParams, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.modelName !== "") {
      writer.uint32(10).string(message.modelName);
    }
    if (message.languageCode !== "") {
      writer.uint32(26).string(message.languageCode);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NLPModelParams {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNLPModelParams();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.modelName = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.languageCode = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NLPModelParams {
    return {
      modelName: isSet(object.modelName) ? globalThis.String(object.modelName) : "",
      languageCode: isSet(object.languageCode) ? globalThis.String(object.languageCode) : "",
    };
  },

  toJSON(message: NLPModelParams): unknown {
    const obj: any = {};
    if (message.modelName !== "") {
      obj.modelName = message.modelName;
    }
    if (message.languageCode !== "") {
      obj.languageCode = message.languageCode;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<NLPModelParams>, I>>(base?: I): NLPModelParams {
    return NLPModelParams.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<NLPModelParams>, I>>(object: I): NLPModelParams {
    const message = createBaseNLPModelParams();
    message.modelName = object.modelName ?? "";
    message.languageCode = object.languageCode ?? "";
    return message;
  },
};

function createBaseTextTransformRequest(): TextTransformRequest {
  return { text: [], topN: 0, model: undefined, id: undefined };
}

export const TextTransformRequest = {
  encode(message: TextTransformRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.text) {
      writer.uint32(10).string(v!);
    }
    if (message.topN !== 0) {
      writer.uint32(16).uint32(message.topN);
    }
    if (message.model !== undefined) {
      NLPModelParams.encode(message.model, writer.uint32(26).fork()).join();
    }
    if (message.id !== undefined) {
      RequestId.encode(message.id, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TextTransformRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTextTransformRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.text.push(reader.string());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.topN = reader.uint32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.model = NLPModelParams.decode(reader, reader.uint32());
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.id = RequestId.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TextTransformRequest {
    return {
      text: globalThis.Array.isArray(object?.text) ? object.text.map((e: any) => globalThis.String(e)) : [],
      topN: isSet(object.topN) ? globalThis.Number(object.topN) : 0,
      model: isSet(object.model) ? NLPModelParams.fromJSON(object.model) : undefined,
      id: isSet(object.id) ? RequestId.fromJSON(object.id) : undefined,
    };
  },

  toJSON(message: TextTransformRequest): unknown {
    const obj: any = {};
    if (message.text?.length) {
      obj.text = message.text;
    }
    if (message.topN !== 0) {
      obj.topN = Math.round(message.topN);
    }
    if (message.model !== undefined) {
      obj.model = NLPModelParams.toJSON(message.model);
    }
    if (message.id !== undefined) {
      obj.id = RequestId.toJSON(message.id);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<TextTransformRequest>, I>>(base?: I): TextTransformRequest {
    return TextTransformRequest.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<TextTransformRequest>, I>>(object: I): TextTransformRequest {
    const message = createBaseTextTransformRequest();
    message.text = object.text?.map((e) => e) || [];
    message.topN = object.topN ?? 0;
    message.model = (object.model !== undefined && object.model !== null)
      ? NLPModelParams.fromPartial(object.model)
      : undefined;
    message.id = (object.id !== undefined && object.id !== null) ? RequestId.fromPartial(object.id) : undefined;
    return message;
  },
};

function createBaseTextTransformResponse(): TextTransformResponse {
  return { text: [], id: undefined };
}

export const TextTransformResponse = {
  encode(message: TextTransformResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.text) {
      writer.uint32(10).string(v!);
    }
    if (message.id !== undefined) {
      RequestId.encode(message.id, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TextTransformResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTextTransformResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.text.push(reader.string());
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.id = RequestId.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TextTransformResponse {
    return {
      text: globalThis.Array.isArray(object?.text) ? object.text.map((e: any) => globalThis.String(e)) : [],
      id: isSet(object.id) ? RequestId.fromJSON(object.id) : undefined,
    };
  },

  toJSON(message: TextTransformResponse): unknown {
    const obj: any = {};
    if (message.text?.length) {
      obj.text = message.text;
    }
    if (message.id !== undefined) {
      obj.id = RequestId.toJSON(message.id);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<TextTransformResponse>, I>>(base?: I): TextTransformResponse {
    return TextTransformResponse.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<TextTransformResponse>, I>>(object: I): TextTransformResponse {
    const message = createBaseTextTransformResponse();
    message.text = object.text?.map((e) => e) || [];
    message.id = (object.id !== undefined && object.id !== null) ? RequestId.fromPartial(object.id) : undefined;
    return message;
  },
};

function createBaseTextClassRequest(): TextClassRequest {
  return { text: [], topN: 0, model: undefined, id: undefined };
}

export const TextClassRequest = {
  encode(message: TextClassRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.text) {
      writer.uint32(10).string(v!);
    }
    if (message.topN !== 0) {
      writer.uint32(16).uint32(message.topN);
    }
    if (message.model !== undefined) {
      NLPModelParams.encode(message.model, writer.uint32(26).fork()).join();
    }
    if (message.id !== undefined) {
      RequestId.encode(message.id, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TextClassRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTextClassRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.text.push(reader.string());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.topN = reader.uint32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.model = NLPModelParams.decode(reader, reader.uint32());
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.id = RequestId.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TextClassRequest {
    return {
      text: globalThis.Array.isArray(object?.text) ? object.text.map((e: any) => globalThis.String(e)) : [],
      topN: isSet(object.topN) ? globalThis.Number(object.topN) : 0,
      model: isSet(object.model) ? NLPModelParams.fromJSON(object.model) : undefined,
      id: isSet(object.id) ? RequestId.fromJSON(object.id) : undefined,
    };
  },

  toJSON(message: TextClassRequest): unknown {
    const obj: any = {};
    if (message.text?.length) {
      obj.text = message.text;
    }
    if (message.topN !== 0) {
      obj.topN = Math.round(message.topN);
    }
    if (message.model !== undefined) {
      obj.model = NLPModelParams.toJSON(message.model);
    }
    if (message.id !== undefined) {
      obj.id = RequestId.toJSON(message.id);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<TextClassRequest>, I>>(base?: I): TextClassRequest {
    return TextClassRequest.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<TextClassRequest>, I>>(object: I): TextClassRequest {
    const message = createBaseTextClassRequest();
    message.text = object.text?.map((e) => e) || [];
    message.topN = object.topN ?? 0;
    message.model = (object.model !== undefined && object.model !== null)
      ? NLPModelParams.fromPartial(object.model)
      : undefined;
    message.id = (object.id !== undefined && object.id !== null) ? RequestId.fromPartial(object.id) : undefined;
    return message;
  },
};

function createBaseClassification(): Classification {
  return { className: "", score: 0 };
}

export const Classification = {
  encode(message: Classification, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.className !== "") {
      writer.uint32(10).string(message.className);
    }
    if (message.score !== 0) {
      writer.uint32(21).float(message.score);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Classification {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseClassification();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.className = reader.string();
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.score = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Classification {
    return {
      className: isSet(object.className) ? globalThis.String(object.className) : "",
      score: isSet(object.score) ? globalThis.Number(object.score) : 0,
    };
  },

  toJSON(message: Classification): unknown {
    const obj: any = {};
    if (message.className !== "") {
      obj.className = message.className;
    }
    if (message.score !== 0) {
      obj.score = message.score;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Classification>, I>>(base?: I): Classification {
    return Classification.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Classification>, I>>(object: I): Classification {
    const message = createBaseClassification();
    message.className = object.className ?? "";
    message.score = object.score ?? 0;
    return message;
  },
};

function createBaseSpan(): Span {
  return { start: 0, end: 0 };
}

export const Span = {
  encode(message: Span, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.start !== 0) {
      writer.uint32(8).uint32(message.start);
    }
    if (message.end !== 0) {
      writer.uint32(16).uint32(message.end);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Span {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSpan();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.start = reader.uint32();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.end = reader.uint32();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Span {
    return {
      start: isSet(object.start) ? globalThis.Number(object.start) : 0,
      end: isSet(object.end) ? globalThis.Number(object.end) : 0,
    };
  },

  toJSON(message: Span): unknown {
    const obj: any = {};
    if (message.start !== 0) {
      obj.start = Math.round(message.start);
    }
    if (message.end !== 0) {
      obj.end = Math.round(message.end);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Span>, I>>(base?: I): Span {
    return Span.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Span>, I>>(object: I): Span {
    const message = createBaseSpan();
    message.start = object.start ?? 0;
    message.end = object.end ?? 0;
    return message;
  },
};

function createBaseClassificationResult(): ClassificationResult {
  return { labels: [] };
}

export const ClassificationResult = {
  encode(message: ClassificationResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.labels) {
      Classification.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ClassificationResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseClassificationResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.labels.push(Classification.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ClassificationResult {
    return {
      labels: globalThis.Array.isArray(object?.labels) ? object.labels.map((e: any) => Classification.fromJSON(e)) : [],
    };
  },

  toJSON(message: ClassificationResult): unknown {
    const obj: any = {};
    if (message.labels?.length) {
      obj.labels = message.labels.map((e) => Classification.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ClassificationResult>, I>>(base?: I): ClassificationResult {
    return ClassificationResult.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ClassificationResult>, I>>(object: I): ClassificationResult {
    const message = createBaseClassificationResult();
    message.labels = object.labels?.map((e) => Classification.fromPartial(e)) || [];
    return message;
  },
};

function createBaseTextClassResponse(): TextClassResponse {
  return { results: [], id: undefined };
}

export const TextClassResponse = {
  encode(message: TextClassResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.results) {
      ClassificationResult.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.id !== undefined) {
      RequestId.encode(message.id, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TextClassResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTextClassResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.results.push(ClassificationResult.decode(reader, reader.uint32()));
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.id = RequestId.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TextClassResponse {
    return {
      results: globalThis.Array.isArray(object?.results)
        ? object.results.map((e: any) => ClassificationResult.fromJSON(e))
        : [],
      id: isSet(object.id) ? RequestId.fromJSON(object.id) : undefined,
    };
  },

  toJSON(message: TextClassResponse): unknown {
    const obj: any = {};
    if (message.results?.length) {
      obj.results = message.results.map((e) => ClassificationResult.toJSON(e));
    }
    if (message.id !== undefined) {
      obj.id = RequestId.toJSON(message.id);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<TextClassResponse>, I>>(base?: I): TextClassResponse {
    return TextClassResponse.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<TextClassResponse>, I>>(object: I): TextClassResponse {
    const message = createBaseTextClassResponse();
    message.results = object.results?.map((e) => ClassificationResult.fromPartial(e)) || [];
    message.id = (object.id !== undefined && object.id !== null) ? RequestId.fromPartial(object.id) : undefined;
    return message;
  },
};

function createBaseTokenClassRequest(): TokenClassRequest {
  return { text: [], topN: 0, model: undefined, id: undefined };
}

export const TokenClassRequest = {
  encode(message: TokenClassRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.text) {
      writer.uint32(10).string(v!);
    }
    if (message.topN !== 0) {
      writer.uint32(24).uint32(message.topN);
    }
    if (message.model !== undefined) {
      NLPModelParams.encode(message.model, writer.uint32(34).fork()).join();
    }
    if (message.id !== undefined) {
      RequestId.encode(message.id, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TokenClassRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTokenClassRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.text.push(reader.string());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.topN = reader.uint32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.model = NLPModelParams.decode(reader, reader.uint32());
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.id = RequestId.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TokenClassRequest {
    return {
      text: globalThis.Array.isArray(object?.text) ? object.text.map((e: any) => globalThis.String(e)) : [],
      topN: isSet(object.topN) ? globalThis.Number(object.topN) : 0,
      model: isSet(object.model) ? NLPModelParams.fromJSON(object.model) : undefined,
      id: isSet(object.id) ? RequestId.fromJSON(object.id) : undefined,
    };
  },

  toJSON(message: TokenClassRequest): unknown {
    const obj: any = {};
    if (message.text?.length) {
      obj.text = message.text;
    }
    if (message.topN !== 0) {
      obj.topN = Math.round(message.topN);
    }
    if (message.model !== undefined) {
      obj.model = NLPModelParams.toJSON(message.model);
    }
    if (message.id !== undefined) {
      obj.id = RequestId.toJSON(message.id);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<TokenClassRequest>, I>>(base?: I): TokenClassRequest {
    return TokenClassRequest.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<TokenClassRequest>, I>>(object: I): TokenClassRequest {
    const message = createBaseTokenClassRequest();
    message.text = object.text?.map((e) => e) || [];
    message.topN = object.topN ?? 0;
    message.model = (object.model !== undefined && object.model !== null)
      ? NLPModelParams.fromPartial(object.model)
      : undefined;
    message.id = (object.id !== undefined && object.id !== null) ? RequestId.fromPartial(object.id) : undefined;
    return message;
  },
};

function createBaseTokenClassValue(): TokenClassValue {
  return { token: "", label: [], span: [] };
}

export const TokenClassValue = {
  encode(message: TokenClassValue, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.token !== "") {
      writer.uint32(10).string(message.token);
    }
    for (const v of message.label) {
      Classification.encode(v!, writer.uint32(18).fork()).join();
    }
    for (const v of message.span) {
      Span.encode(v!, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TokenClassValue {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTokenClassValue();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.token = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.label.push(Classification.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.span.push(Span.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TokenClassValue {
    return {
      token: isSet(object.token) ? globalThis.String(object.token) : "",
      label: globalThis.Array.isArray(object?.label) ? object.label.map((e: any) => Classification.fromJSON(e)) : [],
      span: globalThis.Array.isArray(object?.span) ? object.span.map((e: any) => Span.fromJSON(e)) : [],
    };
  },

  toJSON(message: TokenClassValue): unknown {
    const obj: any = {};
    if (message.token !== "") {
      obj.token = message.token;
    }
    if (message.label?.length) {
      obj.label = message.label.map((e) => Classification.toJSON(e));
    }
    if (message.span?.length) {
      obj.span = message.span.map((e) => Span.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<TokenClassValue>, I>>(base?: I): TokenClassValue {
    return TokenClassValue.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<TokenClassValue>, I>>(object: I): TokenClassValue {
    const message = createBaseTokenClassValue();
    message.token = object.token ?? "";
    message.label = object.label?.map((e) => Classification.fromPartial(e)) || [];
    message.span = object.span?.map((e) => Span.fromPartial(e)) || [];
    return message;
  },
};

function createBaseTokenClassSequence(): TokenClassSequence {
  return { results: [] };
}

export const TokenClassSequence = {
  encode(message: TokenClassSequence, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.results) {
      TokenClassValue.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TokenClassSequence {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTokenClassSequence();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.results.push(TokenClassValue.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TokenClassSequence {
    return {
      results: globalThis.Array.isArray(object?.results)
        ? object.results.map((e: any) => TokenClassValue.fromJSON(e))
        : [],
    };
  },

  toJSON(message: TokenClassSequence): unknown {
    const obj: any = {};
    if (message.results?.length) {
      obj.results = message.results.map((e) => TokenClassValue.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<TokenClassSequence>, I>>(base?: I): TokenClassSequence {
    return TokenClassSequence.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<TokenClassSequence>, I>>(object: I): TokenClassSequence {
    const message = createBaseTokenClassSequence();
    message.results = object.results?.map((e) => TokenClassValue.fromPartial(e)) || [];
    return message;
  },
};

function createBaseTokenClassResponse(): TokenClassResponse {
  return { results: [], id: undefined };
}

export const TokenClassResponse = {
  encode(message: TokenClassResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.results) {
      TokenClassSequence.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.id !== undefined) {
      RequestId.encode(message.id, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TokenClassResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTokenClassResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.results.push(TokenClassSequence.decode(reader, reader.uint32()));
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.id = RequestId.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TokenClassResponse {
    return {
      results: globalThis.Array.isArray(object?.results)
        ? object.results.map((e: any) => TokenClassSequence.fromJSON(e))
        : [],
      id: isSet(object.id) ? RequestId.fromJSON(object.id) : undefined,
    };
  },

  toJSON(message: TokenClassResponse): unknown {
    const obj: any = {};
    if (message.results?.length) {
      obj.results = message.results.map((e) => TokenClassSequence.toJSON(e));
    }
    if (message.id !== undefined) {
      obj.id = RequestId.toJSON(message.id);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<TokenClassResponse>, I>>(base?: I): TokenClassResponse {
    return TokenClassResponse.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<TokenClassResponse>, I>>(object: I): TokenClassResponse {
    const message = createBaseTokenClassResponse();
    message.results = object.results?.map((e) => TokenClassSequence.fromPartial(e)) || [];
    message.id = (object.id !== undefined && object.id !== null) ? RequestId.fromPartial(object.id) : undefined;
    return message;
  },
};

function createBaseAnalyzeIntentContext(): AnalyzeIntentContext {
  return {};
}

export const AnalyzeIntentContext = {
  encode(_: AnalyzeIntentContext, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeIntentContext {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeIntentContext();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): AnalyzeIntentContext {
    return {};
  },

  toJSON(_: AnalyzeIntentContext): unknown {
    const obj: any = {};
    return obj;
  },

  create<I extends Exact<DeepPartial<AnalyzeIntentContext>, I>>(base?: I): AnalyzeIntentContext {
    return AnalyzeIntentContext.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AnalyzeIntentContext>, I>>(_: I): AnalyzeIntentContext {
    const message = createBaseAnalyzeIntentContext();
    return message;
  },
};

function createBaseAnalyzeIntentOptions(): AnalyzeIntentOptions {
  return { previousIntent: undefined, vectors: undefined, domain: "", lang: "" };
}

export const AnalyzeIntentOptions = {
  encode(message: AnalyzeIntentOptions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.previousIntent !== undefined) {
      writer.uint32(10).string(message.previousIntent);
    }
    if (message.vectors !== undefined) {
      AnalyzeIntentContext.encode(message.vectors, writer.uint32(18).fork()).join();
    }
    if (message.domain !== "") {
      writer.uint32(26).string(message.domain);
    }
    if (message.lang !== "") {
      writer.uint32(34).string(message.lang);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeIntentOptions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeIntentOptions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.previousIntent = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.vectors = AnalyzeIntentContext.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.domain = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.lang = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeIntentOptions {
    return {
      previousIntent: isSet(object.previousIntent) ? globalThis.String(object.previousIntent) : undefined,
      vectors: isSet(object.vectors) ? AnalyzeIntentContext.fromJSON(object.vectors) : undefined,
      domain: isSet(object.domain) ? globalThis.String(object.domain) : "",
      lang: isSet(object.lang) ? globalThis.String(object.lang) : "",
    };
  },

  toJSON(message: AnalyzeIntentOptions): unknown {
    const obj: any = {};
    if (message.previousIntent !== undefined) {
      obj.previousIntent = message.previousIntent;
    }
    if (message.vectors !== undefined) {
      obj.vectors = AnalyzeIntentContext.toJSON(message.vectors);
    }
    if (message.domain !== "") {
      obj.domain = message.domain;
    }
    if (message.lang !== "") {
      obj.lang = message.lang;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AnalyzeIntentOptions>, I>>(base?: I): AnalyzeIntentOptions {
    return AnalyzeIntentOptions.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AnalyzeIntentOptions>, I>>(object: I): AnalyzeIntentOptions {
    const message = createBaseAnalyzeIntentOptions();
    message.previousIntent = object.previousIntent ?? undefined;
    message.vectors = (object.vectors !== undefined && object.vectors !== null)
      ? AnalyzeIntentContext.fromPartial(object.vectors)
      : undefined;
    message.domain = object.domain ?? "";
    message.lang = object.lang ?? "";
    return message;
  },
};

function createBaseAnalyzeIntentRequest(): AnalyzeIntentRequest {
  return { query: "", options: undefined, id: undefined };
}

export const AnalyzeIntentRequest = {
  encode(message: AnalyzeIntentRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.query !== "") {
      writer.uint32(10).string(message.query);
    }
    if (message.options !== undefined) {
      AnalyzeIntentOptions.encode(message.options, writer.uint32(18).fork()).join();
    }
    if (message.id !== undefined) {
      RequestId.encode(message.id, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeIntentRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeIntentRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.query = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.options = AnalyzeIntentOptions.decode(reader, reader.uint32());
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.id = RequestId.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeIntentRequest {
    return {
      query: isSet(object.query) ? globalThis.String(object.query) : "",
      options: isSet(object.options) ? AnalyzeIntentOptions.fromJSON(object.options) : undefined,
      id: isSet(object.id) ? RequestId.fromJSON(object.id) : undefined,
    };
  },

  toJSON(message: AnalyzeIntentRequest): unknown {
    const obj: any = {};
    if (message.query !== "") {
      obj.query = message.query;
    }
    if (message.options !== undefined) {
      obj.options = AnalyzeIntentOptions.toJSON(message.options);
    }
    if (message.id !== undefined) {
      obj.id = RequestId.toJSON(message.id);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AnalyzeIntentRequest>, I>>(base?: I): AnalyzeIntentRequest {
    return AnalyzeIntentRequest.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AnalyzeIntentRequest>, I>>(object: I): AnalyzeIntentRequest {
    const message = createBaseAnalyzeIntentRequest();
    message.query = object.query ?? "";
    message.options = (object.options !== undefined && object.options !== null)
      ? AnalyzeIntentOptions.fromPartial(object.options)
      : undefined;
    message.id = (object.id !== undefined && object.id !== null) ? RequestId.fromPartial(object.id) : undefined;
    return message;
  },
};

function createBaseAnalyzeIntentResponse(): AnalyzeIntentResponse {
  return { intent: undefined, slots: [], domainStr: "", domain: undefined, id: undefined };
}

export const AnalyzeIntentResponse = {
  encode(message: AnalyzeIntentResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.intent !== undefined) {
      Classification.encode(message.intent, writer.uint32(10).fork()).join();
    }
    for (const v of message.slots) {
      TokenClassValue.encode(v!, writer.uint32(18).fork()).join();
    }
    if (message.domainStr !== "") {
      writer.uint32(26).string(message.domainStr);
    }
    if (message.domain !== undefined) {
      Classification.encode(message.domain, writer.uint32(34).fork()).join();
    }
    if (message.id !== undefined) {
      RequestId.encode(message.id, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeIntentResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeIntentResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.intent = Classification.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.slots.push(TokenClassValue.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.domainStr = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.domain = Classification.decode(reader, reader.uint32());
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.id = RequestId.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeIntentResponse {
    return {
      intent: isSet(object.intent) ? Classification.fromJSON(object.intent) : undefined,
      slots: globalThis.Array.isArray(object?.slots) ? object.slots.map((e: any) => TokenClassValue.fromJSON(e)) : [],
      domainStr: isSet(object.domainStr) ? globalThis.String(object.domainStr) : "",
      domain: isSet(object.domain) ? Classification.fromJSON(object.domain) : undefined,
      id: isSet(object.id) ? RequestId.fromJSON(object.id) : undefined,
    };
  },

  toJSON(message: AnalyzeIntentResponse): unknown {
    const obj: any = {};
    if (message.intent !== undefined) {
      obj.intent = Classification.toJSON(message.intent);
    }
    if (message.slots?.length) {
      obj.slots = message.slots.map((e) => TokenClassValue.toJSON(e));
    }
    if (message.domainStr !== "") {
      obj.domainStr = message.domainStr;
    }
    if (message.domain !== undefined) {
      obj.domain = Classification.toJSON(message.domain);
    }
    if (message.id !== undefined) {
      obj.id = RequestId.toJSON(message.id);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AnalyzeIntentResponse>, I>>(base?: I): AnalyzeIntentResponse {
    return AnalyzeIntentResponse.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AnalyzeIntentResponse>, I>>(object: I): AnalyzeIntentResponse {
    const message = createBaseAnalyzeIntentResponse();
    message.intent = (object.intent !== undefined && object.intent !== null)
      ? Classification.fromPartial(object.intent)
      : undefined;
    message.slots = object.slots?.map((e) => TokenClassValue.fromPartial(e)) || [];
    message.domainStr = object.domainStr ?? "";
    message.domain = (object.domain !== undefined && object.domain !== null)
      ? Classification.fromPartial(object.domain)
      : undefined;
    message.id = (object.id !== undefined && object.id !== null) ? RequestId.fromPartial(object.id) : undefined;
    return message;
  },
};

function createBaseAnalyzeEntitiesOptions(): AnalyzeEntitiesOptions {
  return { lang: "" };
}

export const AnalyzeEntitiesOptions = {
  encode(message: AnalyzeEntitiesOptions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.lang !== "") {
      writer.uint32(34).string(message.lang);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeEntitiesOptions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeEntitiesOptions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 4:
          if (tag !== 34) {
            break;
          }

          message.lang = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeEntitiesOptions {
    return { lang: isSet(object.lang) ? globalThis.String(object.lang) : "" };
  },

  toJSON(message: AnalyzeEntitiesOptions): unknown {
    const obj: any = {};
    if (message.lang !== "") {
      obj.lang = message.lang;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AnalyzeEntitiesOptions>, I>>(base?: I): AnalyzeEntitiesOptions {
    return AnalyzeEntitiesOptions.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AnalyzeEntitiesOptions>, I>>(object: I): AnalyzeEntitiesOptions {
    const message = createBaseAnalyzeEntitiesOptions();
    message.lang = object.lang ?? "";
    return message;
  },
};

function createBaseAnalyzeEntitiesRequest(): AnalyzeEntitiesRequest {
  return { query: "", options: undefined, id: undefined };
}

export const AnalyzeEntitiesRequest = {
  encode(message: AnalyzeEntitiesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.query !== "") {
      writer.uint32(10).string(message.query);
    }
    if (message.options !== undefined) {
      AnalyzeEntitiesOptions.encode(message.options, writer.uint32(18).fork()).join();
    }
    if (message.id !== undefined) {
      RequestId.encode(message.id, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnalyzeEntitiesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeEntitiesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.query = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.options = AnalyzeEntitiesOptions.decode(reader, reader.uint32());
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.id = RequestId.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeEntitiesRequest {
    return {
      query: isSet(object.query) ? globalThis.String(object.query) : "",
      options: isSet(object.options) ? AnalyzeEntitiesOptions.fromJSON(object.options) : undefined,
      id: isSet(object.id) ? RequestId.fromJSON(object.id) : undefined,
    };
  },

  toJSON(message: AnalyzeEntitiesRequest): unknown {
    const obj: any = {};
    if (message.query !== "") {
      obj.query = message.query;
    }
    if (message.options !== undefined) {
      obj.options = AnalyzeEntitiesOptions.toJSON(message.options);
    }
    if (message.id !== undefined) {
      obj.id = RequestId.toJSON(message.id);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AnalyzeEntitiesRequest>, I>>(base?: I): AnalyzeEntitiesRequest {
    return AnalyzeEntitiesRequest.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AnalyzeEntitiesRequest>, I>>(object: I): AnalyzeEntitiesRequest {
    const message = createBaseAnalyzeEntitiesRequest();
    message.query = object.query ?? "";
    message.options = (object.options !== undefined && object.options !== null)
      ? AnalyzeEntitiesOptions.fromPartial(object.options)
      : undefined;
    message.id = (object.id !== undefined && object.id !== null) ? RequestId.fromPartial(object.id) : undefined;
    return message;
  },
};

function createBaseNaturalQueryRequest(): NaturalQueryRequest {
  return { query: "", topN: 0, context: "", id: undefined };
}

export const NaturalQueryRequest = {
  encode(message: NaturalQueryRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.query !== "") {
      writer.uint32(10).string(message.query);
    }
    if (message.topN !== 0) {
      writer.uint32(16).uint32(message.topN);
    }
    if (message.context !== "") {
      writer.uint32(26).string(message.context);
    }
    if (message.id !== undefined) {
      RequestId.encode(message.id, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NaturalQueryRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNaturalQueryRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.query = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.topN = reader.uint32();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.context = reader.string();
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.id = RequestId.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NaturalQueryRequest {
    return {
      query: isSet(object.query) ? globalThis.String(object.query) : "",
      topN: isSet(object.topN) ? globalThis.Number(object.topN) : 0,
      context: isSet(object.context) ? globalThis.String(object.context) : "",
      id: isSet(object.id) ? RequestId.fromJSON(object.id) : undefined,
    };
  },

  toJSON(message: NaturalQueryRequest): unknown {
    const obj: any = {};
    if (message.query !== "") {
      obj.query = message.query;
    }
    if (message.topN !== 0) {
      obj.topN = Math.round(message.topN);
    }
    if (message.context !== "") {
      obj.context = message.context;
    }
    if (message.id !== undefined) {
      obj.id = RequestId.toJSON(message.id);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<NaturalQueryRequest>, I>>(base?: I): NaturalQueryRequest {
    return NaturalQueryRequest.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<NaturalQueryRequest>, I>>(object: I): NaturalQueryRequest {
    const message = createBaseNaturalQueryRequest();
    message.query = object.query ?? "";
    message.topN = object.topN ?? 0;
    message.context = object.context ?? "";
    message.id = (object.id !== undefined && object.id !== null) ? RequestId.fromPartial(object.id) : undefined;
    return message;
  },
};

function createBaseNaturalQueryResult(): NaturalQueryResult {
  return { answer: "", score: 0 };
}

export const NaturalQueryResult = {
  encode(message: NaturalQueryResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.answer !== "") {
      writer.uint32(10).string(message.answer);
    }
    if (message.score !== 0) {
      writer.uint32(21).float(message.score);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NaturalQueryResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNaturalQueryResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.answer = reader.string();
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.score = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NaturalQueryResult {
    return {
      answer: isSet(object.answer) ? globalThis.String(object.answer) : "",
      score: isSet(object.score) ? globalThis.Number(object.score) : 0,
    };
  },

  toJSON(message: NaturalQueryResult): unknown {
    const obj: any = {};
    if (message.answer !== "") {
      obj.answer = message.answer;
    }
    if (message.score !== 0) {
      obj.score = message.score;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<NaturalQueryResult>, I>>(base?: I): NaturalQueryResult {
    return NaturalQueryResult.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<NaturalQueryResult>, I>>(object: I): NaturalQueryResult {
    const message = createBaseNaturalQueryResult();
    message.answer = object.answer ?? "";
    message.score = object.score ?? 0;
    return message;
  },
};

function createBaseNaturalQueryResponse(): NaturalQueryResponse {
  return { results: [], id: undefined };
}

export const NaturalQueryResponse = {
  encode(message: NaturalQueryResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.results) {
      NaturalQueryResult.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.id !== undefined) {
      RequestId.encode(message.id, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NaturalQueryResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNaturalQueryResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.results.push(NaturalQueryResult.decode(reader, reader.uint32()));
          continue;
        case 100:
          if (tag !== 802) {
            break;
          }

          message.id = RequestId.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NaturalQueryResponse {
    return {
      results: globalThis.Array.isArray(object?.results)
        ? object.results.map((e: any) => NaturalQueryResult.fromJSON(e))
        : [],
      id: isSet(object.id) ? RequestId.fromJSON(object.id) : undefined,
    };
  },

  toJSON(message: NaturalQueryResponse): unknown {
    const obj: any = {};
    if (message.results?.length) {
      obj.results = message.results.map((e) => NaturalQueryResult.toJSON(e));
    }
    if (message.id !== undefined) {
      obj.id = RequestId.toJSON(message.id);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<NaturalQueryResponse>, I>>(base?: I): NaturalQueryResponse {
    return NaturalQueryResponse.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<NaturalQueryResponse>, I>>(object: I): NaturalQueryResponse {
    const message = createBaseNaturalQueryResponse();
    message.results = object.results?.map((e) => NaturalQueryResult.fromPartial(e)) || [];
    message.id = (object.id !== undefined && object.id !== null) ? RequestId.fromPartial(object.id) : undefined;
    return message;
  },
};

export type RivaLanguageUnderstandingService = typeof RivaLanguageUnderstandingService;
export const RivaLanguageUnderstandingService = {
  /**
   * ClassifyText takes as input an input/query string and parameters related
   * to the requested model to use to evaluate the text. The service evaluates
   * the text with the requested model, and returns one or more classifications.
   *
   * @deprecated
   */
  classifyText: {
    path: "/nvidia.riva.nlp.RivaLanguageUnderstanding/ClassifyText",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: TextClassRequest) => Buffer.from(TextClassRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => TextClassRequest.decode(value),
    responseSerialize: (value: TextClassResponse) => Buffer.from(TextClassResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => TextClassResponse.decode(value),
  },
  /**
   * ClassifyTokens takes as input either a string or list of tokens and
   * parameters related to which model to use. The service evaluates the text
   * with the requested model, performing additional tokenization if necessary,
   * and returns one or more class labels per token.
   *
   * @deprecated
   */
  classifyTokens: {
    path: "/nvidia.riva.nlp.RivaLanguageUnderstanding/ClassifyTokens",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: TokenClassRequest) => Buffer.from(TokenClassRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => TokenClassRequest.decode(value),
    responseSerialize: (value: TokenClassResponse) => Buffer.from(TokenClassResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => TokenClassResponse.decode(value),
  },
  /**
   * TransformText takes an input/query string and parameters related to the
   * requested model and returns another string. The behavior of the function
   * is defined entirely by the underlying model and may be used for
   * tasks like translation, adding punctuation, augment the input directly,
   * etc.
   */
  transformText: {
    path: "/nvidia.riva.nlp.RivaLanguageUnderstanding/TransformText",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: TextTransformRequest) => Buffer.from(TextTransformRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => TextTransformRequest.decode(value),
    responseSerialize: (value: TextTransformResponse) => Buffer.from(TextTransformResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => TextTransformResponse.decode(value),
  },
  /**
   * AnalyzeEntities accepts an input string and returns all named entities
   * within the text, as well as a category and likelihood.
   *
   * @deprecated
   */
  analyzeEntities: {
    path: "/nvidia.riva.nlp.RivaLanguageUnderstanding/AnalyzeEntities",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: AnalyzeEntitiesRequest) => Buffer.from(AnalyzeEntitiesRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => AnalyzeEntitiesRequest.decode(value),
    responseSerialize: (value: TokenClassResponse) => Buffer.from(TokenClassResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => TokenClassResponse.decode(value),
  },
  /**
   * AnalyzeIntent accepts an input string and returns the most likely
   * intent as well as slots relevant to that intent.
   *
   * The model requires that a valid "domain" be passed in, and optionally
   * supports including a previous intent classification result to provide
   * context for the model.
   *
   * @deprecated
   */
  analyzeIntent: {
    path: "/nvidia.riva.nlp.RivaLanguageUnderstanding/AnalyzeIntent",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: AnalyzeIntentRequest) => Buffer.from(AnalyzeIntentRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => AnalyzeIntentRequest.decode(value),
    responseSerialize: (value: AnalyzeIntentResponse) => Buffer.from(AnalyzeIntentResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => AnalyzeIntentResponse.decode(value),
  },
  /**
   * PunctuateText takes text with no- or limited- punctuation and returns
   * the same text with corrected punctuation and capitalization.
   */
  punctuateText: {
    path: "/nvidia.riva.nlp.RivaLanguageUnderstanding/PunctuateText",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: TextTransformRequest) => Buffer.from(TextTransformRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => TextTransformRequest.decode(value),
    responseSerialize: (value: TextTransformResponse) => Buffer.from(TextTransformResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => TextTransformResponse.decode(value),
  },
  /**
   * NaturalQuery is a search function that enables querying one or more
   * documents or contexts with a query that is written in natural language.
   *
   * @deprecated
   */
  naturalQuery: {
    path: "/nvidia.riva.nlp.RivaLanguageUnderstanding/NaturalQuery",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: NaturalQueryRequest) => Buffer.from(NaturalQueryRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => NaturalQueryRequest.decode(value),
    responseSerialize: (value: NaturalQueryResponse) => Buffer.from(NaturalQueryResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => NaturalQueryResponse.decode(value),
  },
  /**
   * Enables clients to request the configuration of the current ASR service, or
   * a specific model within the service.
   */
  getRivaNlpConfig: {
    path: "/nvidia.riva.nlp.RivaLanguageUnderstanding/GetRivaNLPConfig",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: RivaNLPConfigRequest) => Buffer.from(RivaNLPConfigRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => RivaNLPConfigRequest.decode(value),
    responseSerialize: (value: RivaNLPConfigResponse) => Buffer.from(RivaNLPConfigResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => RivaNLPConfigResponse.decode(value),
  },
} as const;

export interface RivaLanguageUnderstandingServer extends UntypedServiceImplementation {
  /**
   * ClassifyText takes as input an input/query string and parameters related
   * to the requested model to use to evaluate the text. The service evaluates
   * the text with the requested model, and returns one or more classifications.
   *
   * @deprecated
   */
  classifyText: handleUnaryCall<TextClassRequest, TextClassResponse>;
  /**
   * ClassifyTokens takes as input either a string or list of tokens and
   * parameters related to which model to use. The service evaluates the text
   * with the requested model, performing additional tokenization if necessary,
   * and returns one or more class labels per token.
   *
   * @deprecated
   */
  classifyTokens: handleUnaryCall<TokenClassRequest, TokenClassResponse>;
  /**
   * TransformText takes an input/query string and parameters related to the
   * requested model and returns another string. The behavior of the function
   * is defined entirely by the underlying model and may be used for
   * tasks like translation, adding punctuation, augment the input directly,
   * etc.
   */
  transformText: handleUnaryCall<TextTransformRequest, TextTransformResponse>;
  /**
   * AnalyzeEntities accepts an input string and returns all named entities
   * within the text, as well as a category and likelihood.
   *
   * @deprecated
   */
  analyzeEntities: handleUnaryCall<AnalyzeEntitiesRequest, TokenClassResponse>;
  /**
   * AnalyzeIntent accepts an input string and returns the most likely
   * intent as well as slots relevant to that intent.
   *
   * The model requires that a valid "domain" be passed in, and optionally
   * supports including a previous intent classification result to provide
   * context for the model.
   *
   * @deprecated
   */
  analyzeIntent: handleUnaryCall<AnalyzeIntentRequest, AnalyzeIntentResponse>;
  /**
   * PunctuateText takes text with no- or limited- punctuation and returns
   * the same text with corrected punctuation and capitalization.
   */
  punctuateText: handleUnaryCall<TextTransformRequest, TextTransformResponse>;
  /**
   * NaturalQuery is a search function that enables querying one or more
   * documents or contexts with a query that is written in natural language.
   *
   * @deprecated
   */
  naturalQuery: handleUnaryCall<NaturalQueryRequest, NaturalQueryResponse>;
  /**
   * Enables clients to request the configuration of the current ASR service, or
   * a specific model within the service.
   */
  getRivaNlpConfig: handleUnaryCall<RivaNLPConfigRequest, RivaNLPConfigResponse>;
}

export interface RivaLanguageUnderstandingClient extends Client {
  /**
   * ClassifyText takes as input an input/query string and parameters related
   * to the requested model to use to evaluate the text. The service evaluates
   * the text with the requested model, and returns one or more classifications.
   *
   * @deprecated
   */
  classifyText(
    request: TextClassRequest,
    callback: (error: ServiceError | null, response: TextClassResponse) => void,
  ): ClientUnaryCall;
  classifyText(
    request: TextClassRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: TextClassResponse) => void,
  ): ClientUnaryCall;
  classifyText(
    request: TextClassRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: TextClassResponse) => void,
  ): ClientUnaryCall;
  /**
   * ClassifyTokens takes as input either a string or list of tokens and
   * parameters related to which model to use. The service evaluates the text
   * with the requested model, performing additional tokenization if necessary,
   * and returns one or more class labels per token.
   *
   * @deprecated
   */
  classifyTokens(
    request: TokenClassRequest,
    callback: (error: ServiceError | null, response: TokenClassResponse) => void,
  ): ClientUnaryCall;
  classifyTokens(
    request: TokenClassRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: TokenClassResponse) => void,
  ): ClientUnaryCall;
  classifyTokens(
    request: TokenClassRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: TokenClassResponse) => void,
  ): ClientUnaryCall;
  /**
   * TransformText takes an input/query string and parameters related to the
   * requested model and returns another string. The behavior of the function
   * is defined entirely by the underlying model and may be used for
   * tasks like translation, adding punctuation, augment the input directly,
   * etc.
   */
  transformText(
    request: TextTransformRequest,
    callback: (error: ServiceError | null, response: TextTransformResponse) => void,
  ): ClientUnaryCall;
  transformText(
    request: TextTransformRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: TextTransformResponse) => void,
  ): ClientUnaryCall;
  transformText(
    request: TextTransformRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: TextTransformResponse) => void,
  ): ClientUnaryCall;
  /**
   * AnalyzeEntities accepts an input string and returns all named entities
   * within the text, as well as a category and likelihood.
   *
   * @deprecated
   */
  analyzeEntities(
    request: AnalyzeEntitiesRequest,
    callback: (error: ServiceError | null, response: TokenClassResponse) => void,
  ): ClientUnaryCall;
  analyzeEntities(
    request: AnalyzeEntitiesRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: TokenClassResponse) => void,
  ): ClientUnaryCall;
  analyzeEntities(
    request: AnalyzeEntitiesRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: TokenClassResponse) => void,
  ): ClientUnaryCall;
  /**
   * AnalyzeIntent accepts an input string and returns the most likely
   * intent as well as slots relevant to that intent.
   *
   * The model requires that a valid "domain" be passed in, and optionally
   * supports including a previous intent classification result to provide
   * context for the model.
   *
   * @deprecated
   */
  analyzeIntent(
    request: AnalyzeIntentRequest,
    callback: (error: ServiceError | null, response: AnalyzeIntentResponse) => void,
  ): ClientUnaryCall;
  analyzeIntent(
    request: AnalyzeIntentRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: AnalyzeIntentResponse) => void,
  ): ClientUnaryCall;
  analyzeIntent(
    request: AnalyzeIntentRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: AnalyzeIntentResponse) => void,
  ): ClientUnaryCall;
  /**
   * PunctuateText takes text with no- or limited- punctuation and returns
   * the same text with corrected punctuation and capitalization.
   */
  punctuateText(
    request: TextTransformRequest,
    callback: (error: ServiceError | null, response: TextTransformResponse) => void,
  ): ClientUnaryCall;
  punctuateText(
    request: TextTransformRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: TextTransformResponse) => void,
  ): ClientUnaryCall;
  punctuateText(
    request: TextTransformRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: TextTransformResponse) => void,
  ): ClientUnaryCall;
  /**
   * NaturalQuery is a search function that enables querying one or more
   * documents or contexts with a query that is written in natural language.
   *
   * @deprecated
   */
  naturalQuery(
    request: NaturalQueryRequest,
    callback: (error: ServiceError | null, response: NaturalQueryResponse) => void,
  ): ClientUnaryCall;
  naturalQuery(
    request: NaturalQueryRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: NaturalQueryResponse) => void,
  ): ClientUnaryCall;
  naturalQuery(
    request: NaturalQueryRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: NaturalQueryResponse) => void,
  ): ClientUnaryCall;
  /**
   * Enables clients to request the configuration of the current ASR service, or
   * a specific model within the service.
   */
  getRivaNlpConfig(
    request: RivaNLPConfigRequest,
    callback: (error: ServiceError | null, response: RivaNLPConfigResponse) => void,
  ): ClientUnaryCall;
  getRivaNlpConfig(
    request: RivaNLPConfigRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: RivaNLPConfigResponse) => void,
  ): ClientUnaryCall;
  getRivaNlpConfig(
    request: RivaNLPConfigRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: RivaNLPConfigResponse) => void,
  ): ClientUnaryCall;
}

export const RivaLanguageUnderstandingClient = makeGenericClientConstructor(
  RivaLanguageUnderstandingService,
  "nvidia.riva.nlp.RivaLanguageUnderstanding",
) as unknown as {
  new (
    address: string,
    credentials: ChannelCredentials,
    options?: Partial<ClientOptions>,
  ): RivaLanguageUnderstandingClient;
  service: typeof RivaLanguageUnderstandingService;
  serviceName: string;
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

type KeysOfUnion<T> = T extends T ? keyof T : never;
export type Exact<P, I extends P> = P extends Builtin ? P
  : P & { [K in keyof P]: Exact<P[K], I[K]> } & { [K in Exclude<keyof I, KeysOfUnion<P>>]: never };

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}
